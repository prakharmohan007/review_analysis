{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import re, sys\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>predicted_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>good quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>peanuts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>best almonds ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>not what expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id   ProductId          UserId  \\\n",
       "0           0   1  B001E4KFG0  A3SGXH7AUHU8GW   \n",
       "1           1   2  B00813GRG4  A1D87F6ZCVE5NK   \n",
       "2           2   3  B000LQOCH0   ABXLMWJIXXAIN   \n",
       "3           3   4  B000UA0QIQ  A395BORC6FGVXV   \n",
       "4           4   5  B006K2ZZ7K  A1UQRSCLF8GW1T   \n",
       "\n",
       "                       ProfileName  HelpfulnessNumerator  \\\n",
       "0                       delmartian                     1   \n",
       "1                           dll pa                     0   \n",
       "2  Natalia Corres \"Natalia Corres\"                     1   \n",
       "3                             Karl                     3   \n",
       "4    Michael D. Bigham \"M. Wassir\"                     0   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      5  1303862400  Good Quality Dog Food   \n",
       "1                       0      1  1346976000      Not as Advertised   \n",
       "2                       1      4  1219017600  \"Delight\" says it all   \n",
       "3                       3      2  1307923200         Cough Medicine   \n",
       "4                       0      5  1350777600            Great taffy   \n",
       "\n",
       "                                                Text   predicted_summary  \n",
       "0  I have bought several of the Vitality canned d...        good quality  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...             peanuts  \n",
       "2  This is a confection that has been around a fe...   best almonds ever  \n",
       "3  If you are looking for the secret ingredient i...   not what expected  \n",
       "4  Great taffy at a great price.  There was a wid...               great  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Reviews_summaries.csv\",engine='python')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[['Score', 'Text','Summary','predicted_summary']]\n",
    "df = df[pd.notnull(df['Text'])]\n",
    "df = df[pd.notnull(df['Summary'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Train and Test Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(df)))\n",
    "train_len = int(len(shuffle_indices) * 0.8)\n",
    "train_indices = shuffle_indices[:train_len]\n",
    "test_indices = shuffle_indices[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_indices.npy',train_indices)\n",
    "np.save('test_indices.npy',test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = df['Text'].values\n",
    "summary_data = df['predicted_summary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_data(text_data):\n",
    "    x_text = [s.strip() for s in text_data]\n",
    "    x_text = [clean_str(sent) for sent in x_text]\n",
    "    x_text = [s.split(\" \") for s in x_text]\n",
    "    return x_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text_review = load_text_data(text_data)\n",
    "x_gen_summary = load_text_data(summary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentences(sentences, padding_word=\"<PAD/>\"):\n",
    "    sequence_length = max(len(x) for x in sentences)\n",
    "    padded_sentences = []\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        num_padding = sequence_length - len(sentence)\n",
    "        new_sentence = sentence + [padding_word] * num_padding\n",
    "        padded_sentences.append(new_sentence)\n",
    "    return padded_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text_review = pad_sentences(x_text_review)\n",
    "x_gen_summary = pad_sentences(x_gen_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Vocabulary for Text reviews and Generated summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary mapping from word to index based on the sentences.\n",
    "    Returns vocabulary mapping and inverse vocabulary mapping.\n",
    "    \"\"\"\n",
    "    # Build vocabulary\n",
    "    word_counts = Counter(itertools.chain(*sentences))\n",
    "    # Mapping from index to word\n",
    "    vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "    # Mapping from word to index\n",
    "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "    return [vocabulary, vocabulary_inv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_text_review, vocabulary_inv_text_review = build_vocab(x_text_review)\n",
    "vocabulary_gen_summary, vocabulary_inv_gen_summary = build_vocab(x_gen_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_data(sentences, vocabulary):\n",
    "    \"\"\"\n",
    "    Maps sentencs and labels to vectors based on a vocabulary.\n",
    "    \"\"\"\n",
    "    x = np.array([[vocabulary[word] for word in sentence] for sentence in sentences])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text_review = build_input_data(x_text_review, vocabulary_text_review)\n",
    "x_gen_summary = build_input_data(x_gen_summary, vocabulary_gen_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('text_review.npy',x_text_review)\n",
    "np.save('predicted_summary_x.npy',x_gen_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ratings.npy',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_review_vocabulary.pkl', 'wb') as f:\n",
    "    pickle.dump(vocabulary_text_review, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('predicted_summary_vocabulary.pkl', 'wb') as f:\n",
    "    pickle.dump(vocabulary_gen_summary, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('text_review_vocabulary_inv.npy',vocabulary_inv_text_review)\n",
    "np.save('predicted_summary_vocabulary_inv.npy',vocabulary_inv_gen_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
