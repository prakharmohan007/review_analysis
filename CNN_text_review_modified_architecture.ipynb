{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re, sys\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gensim\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text_review = np.load('text_review.npy')\n",
    "ratings = np.load('ratings.npy')\n",
    "vocabulary_inv_text_review = np.load('text_review_vocabulary_inv.npy')\n",
    "with open('text_review_vocabulary.pkl', 'rb') as f:\n",
    "    vocabulary_text_review = pickle.load(f)\n",
    "vocabulary_inv_text_review = {rank: word for rank, word in enumerate(vocabulary_inv_text_review)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.load('train_indices.npy')\n",
    "test_indices = np.load('test_indices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text_review = x_text_review[train_indices]\n",
    "x_test_text_review = x_text_review[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = ratings[train_indices]\n",
    "test_ratings = ratings[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_text_review = x_test_text_review.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_twoclass(y):\n",
    "    res = [0 for i in y]\n",
    "    \n",
    "    for index,i in enumerate(y):\n",
    "        if(i<=3):\n",
    "            res[index] = 0\n",
    "        else:\n",
    "            res[index] = 1\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating labels for each review such that when the rating is greater than 3, it is positive. When it is less than or equal to 3, it is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos_neg_train = convert_to_twoclass(train_ratings)\n",
    "y_pos_neg_test = convert_to_twoclass(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onehot(y):\n",
    "    res = [[0 for j in range(5)] for i in y]\n",
    "    \n",
    "    for index,i in enumerate(y):\n",
    "        res[index][i-1] = 1\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = convert_to_onehot(train_ratings)\n",
    "test_ratings = convert_to_onehot(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_text_review shape: (454741, 3768)\n",
      "train_ratings shape: (454741, 5)\n",
      "y_pos_neg_train shape: (454741,)\n",
      "x_test_text_review shape: (113686, 3768)\n",
      "test_ratings shape: (113686, 5)\n",
      "y_pos_neg_test shape: (113686,)\n",
      "Vocabulary Size: 127686\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train_text_review shape:\", x_train_text_review.shape)\n",
    "print(\"train_ratings shape:\", train_ratings.shape)\n",
    "print(\"y_pos_neg_train shape:\", y_pos_neg_train.shape)\n",
    "print(\"x_test_text_review shape:\", x_test_text_review.shape)\n",
    "print(\"test_ratings shape:\", test_ratings.shape)\n",
    "print(\"y_pos_neg_test shape:\", y_pos_neg_test.shape)\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocabulary_inv_text_review)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to predict whether a review is pos/neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "filter_sizes = (3,5)\n",
    "num_filters = 50\n",
    "dropout_prob = (0.5, 0.5)\n",
    "hidden_dims = 10\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "input_shape = (sequence_length_text_review,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gensim_embedding_weights', 'rb') as f:\n",
    "    embedding_weights = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = Embedding(len(vocabulary_inv_text_review), embedding_dim, input_length=sequence_length_text_review, name=\"embedding\",trainable=False)(model_input)\n",
    "\n",
    "z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([v for v in embedding_weights.values()])\n",
    "embedding_layer = model.get_layer(\"embedding\")\n",
    "embedding_layer.set_weights([weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",keras.metrics.Precision(),keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='models/cnn_pos_neg.hdf5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "    \n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
    "    \n",
    "    EarlyStopping(monitor='val_loss', patience=4, verbose=1),\n",
    "\n",
    "    CSVLogger('./02-metrics.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 3768)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 3768, 300)    38305800    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 3768, 300)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 3766, 50)     45050       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 3764, 50)     75050       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1883, 50)     0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1882, 50)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 94150)        0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 94100)        0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 188250)       0           flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 188250)       0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           1882510     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            11          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 40,308,421\n",
      "Trainable params: 2,002,621\n",
      "Non-trainable params: 38,305,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(x_train_text_review, y_pos_neg_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(x_test_text_review, y_pos_neg_test), verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/cnn_pos_neg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454741/454741 [==============================] - 194s 427us/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions = model.predict(x_train_text_review, batch_size=batch_size,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113686/113686 [==============================] - 49s 427us/step\n"
     ]
    }
   ],
   "source": [
    "valid_predictions = model.predict(x_test_text_review, batch_size=batch_size,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_predictions_pos_neg.npy',train_predictions)\n",
    "np.save('valid_predictions_pos_neg.npy',valid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos_neg_train = np.load('train_predictions_pos_neg.npy')\n",
    "y_pos_neg_test = np.load('valid_predictions_pos_neg.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model which takes input as Text review and whether it is pos/neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "filter_sizes = (3,5)\n",
    "num_filters = 50\n",
    "dropout_prob = (0.5, 0.5)\n",
    "hidden_dims = 10\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "input_shape = (sequence_length_text_review,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = Input(shape=input_shape)\n",
    "model_input2 = Input(shape=(1,))\n",
    "z = Embedding(len(vocabulary_inv_text_review), embedding_dim, input_length=sequence_length_text_review, name=\"embedding\")(model_input)\n",
    "\n",
    "z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "\n",
    "z = Dense(10, activation=\"relu\")(z)\n",
    "merged = Concatenate()([z,model_input2])\n",
    "model_output = Dense(5, activation=\"sigmoid\")(merged)\n",
    "\n",
    "model = Model([model_input,model_input2], model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 3768)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 3768, 300)    38305800    input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 3768, 300)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 3766, 50)     45050       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 3764, 50)     75050       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1883, 50)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1882, 50)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 94150)        0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 94100)        0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 188250)       0           flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 188250)       0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           1882510     dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           110         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 11)           0           dense_10[0][0]                   \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 5)            60          concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 40,308,580\n",
      "Trainable params: 40,308,580\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",keras.metrics.Precision(),keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='models/cnn_text_review_modified_arch.hdf5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "    \n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
    "    \n",
    "    EarlyStopping(monitor='val_loss', patience=4, verbose=1),\n",
    "\n",
    "    CSVLogger('./03-metrics.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit([x_train_text_review,y_pos_neg_train], train_ratings, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=([x_test_text_review,y_pos_neg_test], test_ratings), verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/cnn_text_review_modified_arch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict([x_test_text_review,y_pos_neg_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_prediction_error(predicted_classes,labels):\n",
    "    error = 0\n",
    "    for index,i in enumerate(predicted_classes):\n",
    "        error += abs(labels[index]-i)\n",
    "    \n",
    "    return error/float(len(predicted_classes))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_average(predicted_classes,labels):\n",
    "    acc = 0\n",
    "    for index,i in enumerate(predicted_classes):\n",
    "        if(labels[index]==i):\n",
    "            acc += 1\n",
    "    \n",
    "    return acc/float(len(predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpe = calc_mean_prediction_error(np.argmax(test_predictions,axis=1),np.argmax(test_ratings,axis=1))\n",
    "accuracy = calc_average(np.argmax(test_predictions,axis=1),np.argmax(test_ratings,axis=1))\n",
    "precision_recall = precision_recall_fscore_support(np.argmax(test_ratings,axis=1), np.argmax(test_predictions,axis=1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model based on Text review and pos/neg prediction: 0.7599792410675017\n",
      "Mean Prediction Error for model based on Text review and pos/neg prediction: 0.3613989409425963\n",
      "Precision for model based on Text review and pos/neg prediction: 0.48835704290260573\n",
      "Recall for model based on Text review and pos/neg prediction: 0.5194668078797433\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for model based on Text review and pos/neg prediction:\",accuracy)\n",
    "print(\"Mean Prediction Error for model based on Text review and pos/neg prediction:\",mpe)\n",
    "print(\"Precision for model based on Text review and pos/neg prediction:\",precision_recall[0])\n",
    "print(\"Recall for model based on Text review and pos/neg prediction:\",precision_recall[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
